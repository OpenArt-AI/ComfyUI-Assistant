export const CATEGORY_COMFY_ACADEMY="Comfy Academy"
export const CATEGORY_TEMPLATE="Templates"
export const categories = [CATEGORY_COMFY_ACADEMY, CATEGORY_TEMPLATE]
export const latestVersion = 1;
export const modules = [
    // Comfy Academy
    {
        title:"ComfyUI Intro",
        type:'lesson',
        description:`
We show you the ComfyUI interface and talk about different nodes including KSampler (the single most important node to generate a image), Reroute nodes. We even covered slightly more advanced techniques like how to customize a node and how to group a node.

In the next lesson, we will leverage what we learned in this lesson to build our first workflow together.`,
        videoId:`BT2Kpm1cU-w`,
        categories:[categories[0]],
        initialWorkflow:`{"last_node_id": 9,"last_link_id": 9,"nodes": [{"id": 3,"type": "KSampler","pos": [621,237],"size": {"0": 315,"1": 262},"flags": {},"order": 0,"mode": 0,"inputs": [{"name": "model","type": "MODEL","link": null},{"name": "positive","type": "CONDITIONING","link": null},{"name": "negative","type": "CONDITIONING","link": null},{"name": "latent_image","type": "LATENT","link": null}],"outputs": [{"name": "LATENT","type": "LATENT","links": [],"slot_index": 0}],"properties": {"Node name for S&R": "KSampler"},"widgets_values": [156680208700286,"randomize",20,8,"euler","normal",1]}],"links": [],"groups": [],"config": {},"extra": {},"version": 0.4}`
    },
    {
        title:"Build Your First Workflow",
        type:'lesson',
        description:`In this lesson, you will learn how to build your first workflow and see some fun experiments.

We start with KSampler and build out the first workflow to generate an image based on a text prompt with a given model.

Then we tweaked our workflow to have 3 output images.

Finally, we added ControlNet depth map to create images of the same scenery at different time of the day.
 `,
        videoId:`igOXqGR88KI`,
        categories:[categories[0]],
        initialWorkflow:`{"last_node_id":31,"last_link_id":36,"nodes":[{"id":28,"type":"VAELoader","pos":[1290,290],"size":{"0":315,"1":58},"flags":{},"order":0,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[33],"shape":3}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":24,"type":"CLIPTextEncode","pos":[860,450],"size":{"0":400,"1":200},"flags":{},"order":3,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":27}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[25],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, digital painting, masterpiece"]},{"id":25,"type":"CLIPTextEncode","pos":[860,710],"size":{"0":400,"1":200},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":28}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[26],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["ugly, deformed"]},{"id":22,"type":"KSampler","pos":[1310,480],"size":{"0":315,"1":262},"flags":{},"order":5,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":24,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":25,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":26,"slot_index":2},{"name":"latent_image","type":"LATENT","link":29,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[30],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[1106281217108158,"randomize",25,7,"dpmpp_2m","karras",1]},{"id":26,"type":"EmptyLatentImage","pos":[900,280],"size":{"0":315,"1":106},"flags":{},"order":1,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[29],"shape":3}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,768,1]},{"id":27,"type":"VAEDecode","pos":[1670,380],"size":{"0":210,"1":46},"flags":{},"order":6,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":30},{"name":"vae","type":"VAE","link":33,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[36],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":31,"type":"SaveImage","pos":[1650,560],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":7,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":36}],"properties":{},"widgets_values":["ComfyUI"]},{"id":23,"type":"CheckpointLoaderSimple","pos":[500,530],"size":{"0":315,"1":98},"flags":{},"order":2,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[24],"shape":3},{"name":"CLIP","type":"CLIP","links":[27,28],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":[],"shape":3,"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["dreamshaper_8.safetensors"]}],"links":[[24,23,0,22,0,"MODEL"],[25,24,0,22,1,"CONDITIONING"],[26,25,0,22,2,"CONDITIONING"],[27,23,1,24,0,"CLIP"],[28,23,1,25,0,"CLIP"],[29,26,0,22,3,"LATENT"],[30,22,0,27,0,"LATENT"],[33,28,0,27,1,"VAE"],[36,27,0,31,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}`,
        keyframesWorkflows: {
            10:`{"last_node_id": 9, "last_link_id": 9, "nodes": [], "links": [], "groups": [], "config": {}, "extra": {}, "version": 0.4 }`,
            390:`{"last_node_id":42,"last_link_id":59,"nodes":[{"id":26,"type":"EmptyLatentImage","pos":[418,183],"size":{"0":315,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[29],"shape":3}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,768,1]},{"id":23,"type":"CheckpointLoaderSimple","pos":[10,441],"size":{"0":315,"1":98},"flags":{},"order":1,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[24,37,45],"shape":3},{"name":"CLIP","type":"CLIP","links":[27,28,41,49],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":[],"shape":3,"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["dreamshaper_8.safetensors"]},{"id":28,"type":"VAELoader","pos":[7,595],"size":{"0":315,"1":58},"flags":{},"order":2,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[33,43,51],"shape":3}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":25,"type":"CLIPTextEncode","pos":[380,489],"size":{"0":400,"1":200},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":28}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[26,39,47],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["ugly, deformed"]},{"id":24,"type":"CLIPTextEncode","pos":[860,1050],"size":{"0":400,"1":200},"flags":{},"order":3,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":27}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[25],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, digital painting, masterpiece"]},{"id":31,"type":"SaveImage","pos":[860,140],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":11,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":36}],"properties":{},"widgets_values":["ComfyUI"]},{"id":34,"type":"VAEDecode","pos":[1410,960],"size":{"0":210,"1":46},"flags":{},"order":12,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":42},{"name":"vae","type":"VAE","link":43,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[44],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":35,"type":"SaveImage","pos":[1330,140],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":14,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":44}],"properties":{},"widgets_values":["ComfyUI"]},{"id":38,"type":"VAEDecode","pos":[1850,960],"size":{"0":210,"1":46},"flags":{},"order":13,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":50},{"name":"vae","type":"VAE","link":51,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[52],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":39,"type":"SaveImage","pos":[1770,140],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":15,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":52}],"properties":{},"widgets_values":["ComfyUI"]},{"id":22,"type":"KSampler","pos":[880,650],"size":{"0":315,"1":262},"flags":{},"order":7,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":24,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":25,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":26,"slot_index":2},{"name":"latent_image","type":"LATENT","link":29,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[30,53,54],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[404520270437958,"randomize",20,7,"dpmpp_2m","karras",1]},{"id":36,"type":"KSampler","pos":[1790,650],"size":{"0":315,"1":262},"flags":{},"order":10,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":45,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":46,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":47,"slot_index":2},{"name":"latent_image","type":"LATENT","link":54,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[50],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[820732627807787,"randomize",20,7,"dpmpp_2m","karras",0.75]},{"id":27,"type":"VAEDecode","pos":[940,960],"size":{"0":210,"1":46},"flags":{},"order":8,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":30},{"name":"vae","type":"VAE","link":33,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[36],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":32,"type":"KSampler","pos":[1350,650],"size":{"0":315,"1":262},"flags":{},"order":9,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":37,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":59,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":39,"slot_index":2},{"name":"latent_image","type":"LATENT","link":53,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[42],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[779879935222374,"randomize",20,7,"dpmpp_2m","karras",1]},{"id":33,"type":"CLIPTextEncode","pos":[1330,1050],"size":{"0":400,"1":200},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":41}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[59],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, at night, dark night with stars, digital painting, masterpiece"]},{"id":37,"type":"CLIPTextEncode","pos":[1770,1050],"size":{"0":400,"1":200},"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":49}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[46],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, at sunset with orange sky, digital painting, masterpiece"]}],"links":[[24,23,0,22,0,"MODEL"],[25,24,0,22,1,"CONDITIONING"],[26,25,0,22,2,"CONDITIONING"],[27,23,1,24,0,"CLIP"],[28,23,1,25,0,"CLIP"],[29,26,0,22,3,"LATENT"],[30,22,0,27,0,"LATENT"],[33,28,0,27,1,"VAE"],[36,27,0,31,0,"IMAGE"],[37,23,0,32,0,"MODEL"],[39,25,0,32,2,"CONDITIONING"],[41,23,1,33,0,"CLIP"],[42,32,0,34,0,"LATENT"],[43,28,0,34,1,"VAE"],[44,34,0,35,0,"IMAGE"],[45,23,0,36,0,"MODEL"],[46,37,0,36,1,"CONDITIONING"],[47,25,0,36,2,"CONDITIONING"],[49,23,1,37,0,"CLIP"],[50,36,0,38,0,"LATENT"],[51,28,0,38,1,"VAE"],[52,38,0,39,0,"IMAGE"],[53,22,0,32,3,"LATENT"],[54,22,0,36,3,"LATENT"],[59,33,0,32,1,"CONDITIONING"]],"groups":[],"config":{},"extra":{},"version":0.4}`,
            475:`{"last_node_id":45,"last_link_id":63,"nodes":[{"id":26,"type":"EmptyLatentImage","pos":[418,183],"size":{"0":315,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[29],"shape":3}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,768,1]},{"id":23,"type":"CheckpointLoaderSimple","pos":[10,441],"size":{"0":315,"1":98},"flags":{},"order":1,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[24,37,45],"shape":3},{"name":"CLIP","type":"CLIP","links":[27,28,41,49],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":[],"shape":3,"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["dreamshaper_8.safetensors"]},{"id":28,"type":"VAELoader","pos":[7,595],"size":{"0":315,"1":58},"flags":{},"order":2,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[33,43,51],"shape":3}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":25,"type":"CLIPTextEncode","pos":[380,489],"size":{"0":400,"1":200},"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":28}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[26,39,47],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["ugly, deformed"]},{"id":24,"type":"CLIPTextEncode","pos":[860,1050],"size":{"0":400,"1":200},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":27}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[25],"shape":3}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, digital painting, masterpiece"]},{"id":34,"type":"VAEDecode","pos":[1410,960],"size":{"0":210,"1":46},"flags":{},"order":16,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":42},{"name":"vae","type":"VAE","link":43,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[44],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":38,"type":"VAEDecode","pos":[1850,960],"size":{"0":210,"1":46},"flags":{},"order":17,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":50},{"name":"vae","type":"VAE","link":51,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[52],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":32,"type":"KSampler","pos":[1350,650],"size":{"0":315,"1":262},"flags":{},"order":14,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":37,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":58,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":39,"slot_index":2},{"name":"latent_image","type":"LATENT","link":53,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[42],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[364248276467172,"randomize",20,7,"dpmpp_2m","karras",1]},{"id":37,"type":"CLIPTextEncode","pos":[1770,1050],"size":{"0":400,"1":200},"flags":{},"order":8,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":49}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[63],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, at sunset, digital painting, masterpiece"]},{"id":36,"type":"KSampler","pos":[1790,650],"size":{"0":315,"1":262},"flags":{},"order":15,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":45,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":62,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":47,"slot_index":2},{"name":"latent_image","type":"LATENT","link":54,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[50],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[558547470604681,"randomize",20,7,"dpmpp_2m","karras",1]},{"id":43,"type":"ControlNetApply","pos":[1831,1304],"size":{"0":317.4000244140625,"1":98},"flags":{},"order":13,"mode":0,"inputs":[{"name":"conditioning","type":"CONDITIONING","link":63},{"name":"control_net","type":"CONTROL_NET","link":60},{"name":"image","type":"IMAGE","link":61}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[62],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetApply"},"widgets_values":[0.8300000000000001]},{"id":45,"type":"ControlNetLoader","pos":[1834,1480],"size":{"0":315,"1":58},"flags":{},"order":3,"mode":0,"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[60],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoader"},"widgets_values":["control_depth-fp16.safetensors"]},{"id":42,"type":"ControlNetLoader","pos":[1376,1448],"size":{"0":315,"1":58},"flags":{},"order":4,"mode":0,"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[56],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoader"},"widgets_values":["control_depth-fp16.safetensors"]},{"id":40,"type":"ControlNetApply","pos":[1376,1305],"size":{"0":317.4000244140625,"1":98},"flags":{},"order":12,"mode":0,"inputs":[{"name":"conditioning","type":"CONDITIONING","link":57},{"name":"control_net","type":"CONTROL_NET","link":56},{"name":"image","type":"IMAGE","link":55}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[58],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetApply"},"widgets_values":[0.8300000000000001]},{"id":33,"type":"CLIPTextEncode","pos":[1332,1063],"size":{"0":400,"1":200},"flags":{},"order":7,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":41}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[57],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["mountain landscape, dark blue night, clear sky with stars, digital painting, masterpiece"]},{"id":27,"type":"VAEDecode","pos":[944,958],"size":{"0":210,"1":46},"flags":{},"order":10,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":30},{"name":"vae","type":"VAE","link":33,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[36,55,61],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":31,"type":"SaveImage","pos":[909,113],"size":[333.5714111328125,457.857177734375],"flags":{},"order":11,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":36}],"properties":{},"widgets_values":["ComfyUI"]},{"id":35,"type":"SaveImage","pos":[1258,112],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":18,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":44}],"properties":{},"widgets_values":["ComfyUI"]},{"id":39,"type":"SaveImage","pos":[1604,118],"size":{"0":333.5714111328125,"1":457.857177734375},"flags":{},"order":19,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":52}],"properties":{},"widgets_values":["ComfyUI"]},{"id":22,"type":"KSampler","pos":[880,650],"size":{"0":315,"1":262},"flags":{},"order":9,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":24,"slot_index":0},{"name":"positive","type":"CONDITIONING","link":25,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":26,"slot_index":2},{"name":"latent_image","type":"LATENT","link":29,"slot_index":3}],"outputs":[{"name":"LATENT","type":"LATENT","links":[30,53,54],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[977581853009345,"randomize",20,7,"dpmpp_2m","karras",1]}],"links":[[24,23,0,22,0,"MODEL"],[25,24,0,22,1,"CONDITIONING"],[26,25,0,22,2,"CONDITIONING"],[27,23,1,24,0,"CLIP"],[28,23,1,25,0,"CLIP"],[29,26,0,22,3,"LATENT"],[30,22,0,27,0,"LATENT"],[33,28,0,27,1,"VAE"],[36,27,0,31,0,"IMAGE"],[37,23,0,32,0,"MODEL"],[39,25,0,32,2,"CONDITIONING"],[41,23,1,33,0,"CLIP"],[42,32,0,34,0,"LATENT"],[43,28,0,34,1,"VAE"],[44,34,0,35,0,"IMAGE"],[45,23,0,36,0,"MODEL"],[47,25,0,36,2,"CONDITIONING"],[49,23,1,37,0,"CLIP"],[50,36,0,38,0,"LATENT"],[51,28,0,38,1,"VAE"],[52,38,0,39,0,"IMAGE"],[53,22,0,32,3,"LATENT"],[54,22,0,36,3,"LATENT"],[55,27,0,40,2,"IMAGE"],[56,42,0,40,1,"CONTROL_NET"],[57,33,0,40,0,"CONDITIONING"],[58,40,0,32,1,"CONDITIONING"],[60,45,0,43,1,"CONTROL_NET"],[61,27,0,43,2,"IMAGE"],[62,43,0,36,1,"CONDITIONING"],[63,37,0,43,0,"CONDITIONING"]],"groups":[],"config":{},"extra":{},"version":0.4}`
        }
    },

    // templates
    {
        title:"Basic SD1.5 Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/image_OOJIcZFT_1702943704029_raw.jpg',
        description:`This workflow simply

    - loads a model
    - allows you to enter positive negative prompt
    - allows you to adjust basic configurations like seeds, steps etc

and generates an image.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":14,"last_link_id":11,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[440,360],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":5}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":6,"type":"CLIPTextEncode","pos":[440,140],"size":{"0":370,"1":160},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":3}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":8,"type":"VAEDecode","pos":[1240,280],"size":{"0":140,"1":60},"flags":{},"order":7,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":11}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[9],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":9,"type":"SaveImage","pos":[1430,280],"size":{"0":410,"1":460},"flags":{},"order":8,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":9}],"properties":{},"widgets_values":["Result"]},{"id":5,"type":"EmptyLatentImage","pos":[590,580],"size":{"0":220,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":3,"type":"KSampler","pos":[890,280],"size":{"0":300,"1":262},"flags":{},"order":6,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":1},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":11,"type":"Note","pos":[20,50],"size":{"0":260,"1":140},"flags":{},"order":1,"mode":0,"properties":{"text":""},"widgets_values":["Basic 1.x/2.x workflow\\n======================\\n\\nUse this workflow only if you are sure the base checkpoint embeds a good quality VAE, otherwise check the \\"ext_vae\\" workflow."],"color":"#432","bgcolor":"#653"},{"id":12,"type":"Note","pos":[900,-20],"size":{"0":270,"1":250},"flags":{},"order":2,"mode":0,"properties":{"text":""},"widgets_values":["KSampler\\n========\\n\\nDPMPP_2M / KARRAS is generally a good overall performer and a safe bet but experiment with others!\\n\\nLess \\"predictable\\" samplers are those ending with _SDE and _ANCESTRAL.\\n\\nIf results are underwhelming increase the number of steps (+5 at a time).\\n\\nIf the image looks over-saturated lower the CFG value."],"color":"#432","bgcolor":"#653"},{"id":4,"type":"CheckpointLoaderSimple","pos":[30,280],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":3,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[1],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[3,5],"slot_index":1},{"name":"VAE","type":"VAE","links":[11],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["dreamshaper_8.safetensors"]}],"links":[[1,4,0,3,0,"MODEL"],[2,5,0,3,3,"LATENT"],[3,4,1,6,0,"CLIP"],[4,6,0,3,1,"CONDITIONING"],[5,4,1,7,0,"CLIP"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[9,8,0,9,0,"IMAGE"],[11,4,2,8,1,"VAE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic SD1.5 + VAE Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/webp_3C6Rr-LO_1702933751971_raw.webp',
        description:`This workflow adds an external VAE on top of the <a target="_blank" href="https://openart.ai/workflows/openart/basic-sd15-workflow/lkOtNJ2UexVd6vK0kYhd">basic text-to-image workflow</a>. The VAE model is responsible of converting the latent image into the pixel space. The process is "lossy" and a good VAE model is essential to get good quality images.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":16,"last_link_id":12,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[440,360],"size":{"0":370,"1":160},"flags":{},"order":7,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":5}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":6,"type":"CLIPTextEncode","pos":[440,140],"size":{"0":370,"1":160},"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":3}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":8,"type":"VAEDecode","pos":[1240,280],"size":{"0":140,"1":60},"flags":{},"order":9,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[9],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":9,"type":"SaveImage","pos":[1430,280],"size":{"0":410,"1":460},"flags":{},"order":10,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":9}],"properties":{},"widgets_values":["Result"]},{"id":4,"type":"CheckpointLoaderSimple","pos":[30,280],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":0,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[1],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[3,5],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":5,"type":"EmptyLatentImage","pos":[590,580],"size":{"0":220,"1":106},"flags":{},"order":1,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":3,"type":"KSampler","pos":[890,280],"size":{"0":300,"1":262},"flags":{},"order":8,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":1},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":12,"type":"Note","pos":[900,-20],"size":{"0":270,"1":250},"flags":{},"order":2,"mode":0,"properties":{"text":""},"widgets_values":["KSampler\\n========\\n\\nDPMPP_2M / KARRAS is generally a good overall performer and a safe bet but experiment with others!\\n\\nLess \\"predictable\\" samplers are those ending with _SDE and _ANCESTRAL.\\n\\nIf results are underwhelming increase the number of steps (+5 at a time).\\n\\nIf the image looks over-saturated lower the CFG value."],"color":"#432","bgcolor":"#653"},{"id":15,"type":"VAELoader","pos":[870,600],"size":{"0":315,"1":58},"flags":{},"order":3,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":11,"type":"Note","pos":[20,50],"size":[260,170],"flags":{},"order":4,"mode":0,"properties":{"text":""},"widgets_values":["Basic 1.x/2.x workflow + EXT VAE\\n================================\\n\\nSame as the base workflow with added external VAE. The VAE model is responsible of converting the latent image into the pixel space. The process is \\"lossy\\" and a good VAE model is essential to get good quality images."],"color":"#432","bgcolor":"#653"},{"id":16,"type":"Note","pos":[920,710],"size":{"0":260,"1":170},"flags":{},"order":5,"mode":0,"properties":{"text":""},"widgets_values":["VAE\\n===\\n\\nThe one above is considered a good VAE but there are more. Check in the Checkpoint description on Huggingface or CivitAI if the author suggests a specific VAE."],"color":"#432","bgcolor":"#653"}],"links":[[1,4,0,3,0,"MODEL"],[2,5,0,3,3,"LATENT"],[3,4,1,6,0,"CLIP"],[4,6,0,3,1,"CONDITIONING"],[5,4,1,7,0,"CLIP"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[9,8,0,9,0,"IMAGE"],[12,15,0,8,1,"VAE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic Image Upscale Workflow ",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/webp_dq9KHLx1_1702944090473_raw.webp',
        description:`This is the simplest and probably less expensive method to upscale an image on the pixel level. A lanczos algorithm is used in the pixel space to upscale the image and then a second pass applied to it.

It needs a relatively high denoise which means the final image will be a little different from the source.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":23,"last_link_id":24,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[430,290],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":5}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6,19],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":5,"type":"EmptyLatentImage","pos":[580,510],"size":{"0":220,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":3,"type":"KSampler","pos":[880,210],"size":{"0":300,"1":262},"flags":{},"order":6,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":1},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":15,"type":"VAELoader","pos":[860,530],"size":{"0":315,"1":58},"flags":{},"order":1,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12,15,23],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":19,"type":"VAEEncode","pos":[1690,120],"size":[140,46],"flags":{},"order":10,"mode":0,"inputs":[{"name":"pixels","type":"IMAGE","link":14},{"name":"vae","type":"VAE","link":15}],"outputs":[{"name":"LATENT","type":"LATENT","links":[21],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEEncode"}},{"id":22,"type":"KSampler","pos":[1880,60],"size":{"0":300,"1":262},"flags":{},"order":11,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":17},{"name":"positive","type":"CONDITIONING","link":18},{"name":"negative","type":"CONDITIONING","link":19},{"name":"latent_image","type":"LATENT","link":21}],"outputs":[{"name":"LATENT","type":"LATENT","links":[22],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[904,"fixed",25,6.5,"dpmpp_2m","karras",0.48]},{"id":23,"type":"VAEDecode","pos":[2230,60],"size":[140,46],"flags":{},"order":12,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":22},{"name":"vae","type":"VAE","link":23}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[24],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":9,"type":"SaveImage","pos":[2230,160],"size":[698.1452148437502,753.2806640625001],"flags":{},"order":13,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":24}],"properties":{},"widgets_values":["Result"]},{"id":11,"type":"Note","pos":[20,-90],"size":[322.89542543506394,229.8573122953],"flags":{},"order":2,"mode":0,"properties":{"text":""},"widgets_values":["SIMPLE PIXEL SPACE UPSCALER\\n===========================\\n\\nThis is the simplest and probably less expensive method to upscale an image.\\n\\nA lanczos algorithm it's used in the pixel space to upscale the image and then a second pass applied to it.\\n\\nIt needs a relatively high denoise which means the final image will be a little different from the source."],"color":"#432","bgcolor":"#653"},{"id":6,"type":"CLIPTextEncode","pos":[430,70],"size":{"0":370,"1":160},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":3}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4,18],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":8,"type":"VAEDecode","pos":[1220,210],"size":[140,46],"flags":{},"order":7,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[13,16],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":18,"type":"ImageScaleBy","pos":[1440,120],"size":[210,82],"flags":{},"order":8,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":13}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[14],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ImageScaleBy"},"widgets_values":["lanczos",2]},{"id":20,"type":"PreviewImage","pos":[1440,260],"size":[303.4552148437501,317.88066406250005],"flags":{},"order":9,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":16}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":4,"type":"CheckpointLoaderSimple","pos":[20,190],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":3,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[1,17],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[3,5],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]}],"links":[[1,4,0,3,0,"MODEL"],[2,5,0,3,3,"LATENT"],[3,4,1,6,0,"CLIP"],[4,6,0,3,1,"CONDITIONING"],[5,4,1,7,0,"CLIP"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[12,15,0,8,1,"VAE"],[13,8,0,18,0,"IMAGE"],[14,18,0,19,0,"IMAGE"],[15,15,0,19,1,"VAE"],[16,8,0,20,0,"IMAGE"],[17,4,0,22,0,"MODEL"],[18,6,0,22,1,"CONDITIONING"],[19,7,0,22,2,"CONDITIONING"],[21,19,0,22,3,"LATENT"],[22,22,0,23,0,"LATENT"],[23,15,0,23,1,"VAE"],[24,23,0,9,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}/dreamshaper_8.safetensors"]},{"id":5,"type":"IPAdapterApply","pos":[651,-57],"size":{"0":210,"1":258},"flags":{},"order":9,"mode":0,"inputs":[{"name":"ipadapter","type":"IPADAPTER","link":1},{"name":"clip_vision","type":"CLIP_VISION","link":2},{"name":"image","type":"IMAGE","link":3},{"name":"model","type":"MODEL","link":4},{"name":"attn_mask","type":"MASK","link":null}],"outputs":[{"name":"MODEL","type":"MODEL","links":[7],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"IPAdapterApply"},"widgets_values":[0.85,0,"original",0,1,false]},{"id":3,"type":"IPAdapterModelLoader","pos":[290,60],"size":{"0":300,"1":60},"flags":{},"order":5,"mode":0,"outputs":[{"name":"IPADAPTER","type":"IPADAPTER","links":[1],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"IPAdapterModelLoader"},"widgets_values":["ip-adapter_sd15.safetensors"]},{"id":13,"type":"Note","pos":[131,-270],"size":[456.8177419906998,273.55983091565],"flags":{},"order":6,"mode":0,"properties":{"text":""},"widgets_values":["BASIC IPADAPTER\\n===============\\n\\nBe careful when selecting the models!\\n\\nThe IPAdapter model has to match the CLIP vision encoder and of course the main checkpoint.\\n\\nAll SD15 models and all models ending with \\"vit-h\\" use the SD15 CLIP vision.\\n\\nOne of the SDXL models and all models ending with \\"vit-g\\" use the SDXL CLIP vision.\\n\\nPLUS models use more tokens and are stronger. LIGHT models have a very light impact. FACE and FULL-FACE are only to describe faces (they are not face swap!)"],"color":"#432","bgcolor":"#653"}],"links":[[1,3,0,5,0,"IPADAPTER"],[2,4,0,5,1,"CLIP_VISION"],[3,6,0,5,2,"IMAGE"],[4,1,0,5,3,"MODEL"],[5,1,1,7,0,"CLIP"],[6,1,1,8,0,"CLIP"],[7,5,0,9,0,"MODEL"],[8,7,0,9,1,"CONDITIONING"],[9,8,0,9,2,"CONDITIONING"],[10,10,0,9,3,"LATENT"],[11,9,0,11,0,"LATENT"],[12,2,0,11,1,"VAE"],[13,11,0,12,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Model-based Image Upscale Workflow ",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/image_bDYqWOlI_1702944965033_raw.jpg',
        description:`This workflow loads an existing upscaling model that takes care of the upscaling phase. It's more effective but more expensive than our <a target="_blank" href="https://openart.ai/workflows/openart/basic-image-upscale-workflow/REGMkdFKDcRg4RkpMzvG"> basic image upscaling workflow</a>.

The second pass is performed to add back some sharpness to the image but can be done at a very low denoise.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":32,"last_link_id":38,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[430,290],"size":{"0":370,"1":160},"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":5}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6,19],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":5,"type":"EmptyLatentImage","pos":[580,510],"size":{"0":220,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":6,"type":"CLIPTextEncode","pos":[430,70],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":3}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4,18],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":4,"type":"CheckpointLoaderSimple","pos":[20,190],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":1,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[1,17],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[3,5],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":3,"type":"KSampler","pos":[880,210],"size":{"0":300,"1":262},"flags":{},"order":7,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":1},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":23,"type":"VAEDecode","pos":[2300,160],"size":[140,46],"flags":{},"order":14,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":22},{"name":"vae","type":"VAE","link":23}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[24],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":9,"type":"SaveImage","pos":[2300,270],"size":[698.1452148437502,753.2806640625001],"flags":{},"order":15,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":24}],"properties":{},"widgets_values":["Result"]},{"id":8,"type":"VAEDecode","pos":[1220,210],"size":[140,46],"flags":{},"order":8,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[16,36],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":15,"type":"VAELoader","pos":[860,530],"size":{"0":315,"1":58},"flags":{},"order":2,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12,23,37],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":20,"type":"PreviewImage","pos":[1228,310],"size":[303.4552148437501,317.88066406250005],"flags":{},"order":9,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":16}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":28,"type":"ImageUpscaleWithModel","pos":[1407,119],"size":[230,50],"flags":{},"order":10,"mode":0,"inputs":[{"name":"upscale_model","type":"UPSCALE_MODEL","link":30},{"name":"image","type":"IMAGE","link":36,"slot_index":1}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[33],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ImageUpscaleWithModel"}},{"id":27,"type":"UpscaleModelLoader","pos":[1137,49],"size":{"0":230,"1":60},"flags":{},"order":3,"mode":0,"outputs":[{"name":"UPSCALE_MODEL","type":"UPSCALE_MODEL","links":[30],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"UpscaleModelLoader"},"widgets_values":["4x_foolhardy_Remacri.pth"]},{"id":30,"type":"ImageScaleBy","pos":[1676,101],"size":{"0":210,"1":80},"flags":{},"order":11,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":33}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[32],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ImageScaleBy"},"widgets_values":["nearest-exact",0.5]},{"id":29,"type":"VAEEncode","pos":[1740,233],"size":{"0":140,"1":50},"flags":{},"order":12,"mode":0,"inputs":[{"name":"pixels","type":"IMAGE","link":32},{"name":"vae","type":"VAE","link":37}],"outputs":[{"name":"LATENT","type":"LATENT","links":[38],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEEncode"}},{"id":22,"type":"KSampler","pos":[1950,170],"size":{"0":300,"1":262},"flags":{},"order":13,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":17},{"name":"positive","type":"CONDITIONING","link":18},{"name":"negative","type":"CONDITIONING","link":19},{"name":"latent_image","type":"LATENT","link":38}],"outputs":[{"name":"LATENT","type":"LATENT","links":[22],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[905,"fixed",25,6.5,"dpmpp_2m","karras",0.35000000000000003]},{"id":11,"type":"Note","pos":[25,-35],"size":[317.3923561789769,179.25183105468716],"flags":{},"order":4,"mode":0,"properties":{"text":""},"widgets_values":["PIXEL SPACE UPSCALER WITH MODEL\\n===============================\\n\\nOne of the most effective way to upscale is with a model that takes care of the upscaling phase.\\n\\nThe second pass is performed to add back some sharpness to the image but can be done at a very low denoise."],"color":"#432","bgcolor":"#653"}],"links":[[1,4,0,3,0,"MODEL"],[2,5,0,3,3,"LATENT"],[3,4,1,6,0,"CLIP"],[4,6,0,3,1,"CONDITIONING"],[5,4,1,7,0,"CLIP"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[12,15,0,8,1,"VAE"],[16,8,0,20,0,"IMAGE"],[17,4,0,22,0,"MODEL"],[18,6,0,22,1,"CONDITIONING"],[19,7,0,22,2,"CONDITIONING"],[22,22,0,23,0,"LATENT"],[23,15,0,23,1,"VAE"],[24,23,0,9,0,"IMAGE"],[30,27,0,28,0,"UPSCALE_MODEL"],[32,30,0,29,0,"IMAGE"],[33,28,0,30,0,"IMAGE"],[36,8,0,28,1,"IMAGE"],[37,15,0,29,1,"VAE"],[38,29,0,22,3,"LATENT"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic SDXL + Refiner Workflow ",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/webp_a-dC4aL0_1702943892767_raw.webp',
        description:`This workflow adds a refiner model on topic of the <a target="_blank" href="https://openart.ai/workflows/openart/basic-sdxl-workflow/P8VEtDSQGYf4pOugtnvO"> basic SDXL workflow</a>.

The core of the composition is created by the base SDXL model and the refiner takes care of the minutiae. The refiner helps improve the quality of the generated image.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":46,"last_link_id":76,"nodes":[{"id":4,"type":"CheckpointLoaderSimple","pos":[30,50],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":0,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[53],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[49,50],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sdxl/sd_xl_base_1.0_0.9vae.safetensors"]},{"id":5,"type":"EmptyLatentImage","pos":[860,440],"size":{"0":220,"1":106},"flags":{},"order":1,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[54],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[1024,1024,1]},{"id":35,"type":"Note","pos":[464,-235],"size":[330.7162916580676,95.14419681769738],"flags":{},"order":2,"mode":0,"properties":{"text":""},"widgets_values":["Note that we send the same prompt to both TEXT_G and TEXT_L, you can experiment with different prompts but using the same seems to lead to more predictable results."],"color":"#432","bgcolor":"#653"},{"id":30,"type":"CLIPTextEncodeSDXL","pos":[860,-120],"size":{"0":220,"1":220},"flags":{},"order":14,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":49},{"name":"text_g","type":"STRING","link":45,"widget":{"name":"text_g"},"slot_index":1},{"name":"text_l","type":"STRING","link":46,"widget":{"name":"text_l"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[56],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXL"},"widgets_values":[4096,4096,0,0,4096,4096,"a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k","a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"]},{"id":33,"type":"CLIPTextEncodeSDXL","pos":[860,160],"size":{"0":220,"1":220},"flags":{},"order":15,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":50},{"name":"text_g","type":"STRING","link":47,"widget":{"name":"text_g"},"slot_index":1},{"name":"text_l","type":"STRING","link":48,"widget":{"name":"text_l"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[55],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXL"},"widgets_values":[4096,4096,0,0,4096,4096,"blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch","blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch"]},{"id":31,"type":"PrimitiveNode","pos":[460,-90],"size":[338.2407698942967,179.5812845208606],"flags":{},"order":3,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[45,46,65],"widget":{"name":"text_g"},"slot_index":0}],"title":"positive","properties":{"Run widget replace on values":false},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":32,"type":"PrimitiveNode","pos":[460,180],"size":{"0":338.24078369140625,"1":179.58128356933594},"flags":{},"order":4,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[47,48,66],"widget":{"name":"text_g"},"slot_index":0}],"title":"negative","properties":{"Run widget replace on values":false},"widgets_values":["blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":8,"type":"VAEDecode","pos":[2350,20],"size":{"0":140,"1":60},"flags":{},"order":20,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":69},{"name":"vae","type":"VAE","link":58}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[41],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":28,"type":"SaveImage","pos":[2560,20],"size":[688.1291672363286,728.7603461914064],"flags":{},"order":21,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":41}],"properties":{},"widgets_values":["ComfyUI"]},{"id":43,"type":"PrimitiveNode","pos":[867,596],"size":{"0":210,"1":82},"flags":{},"order":5,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[73,74],"widget":{"name":"steps"},"slot_index":0}],"title":"total steps","properties":{"Run widget replace on values":false},"widgets_values":[30,"fixed"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":37,"type":"VAELoader","pos":[1950,260],"size":{"0":315,"1":58},"flags":{},"order":6,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[58],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["sdxl_vae.safetensors"]},{"id":42,"type":"PrimitiveNode","pos":[868,730],"size":{"0":210,"1":82},"flags":{},"order":7,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[75,76],"widget":{"name":"end_at_step"},"slot_index":0}],"title":"steps spent on base","properties":{"Run widget replace on values":false},"widgets_values":[25,"fixed"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":40,"type":"CLIPTextEncodeSDXLRefiner","pos":[1652,-163],"size":[225.5510620117184,126],"flags":{},"order":16,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":63},{"name":"text","type":"STRING","link":65,"widget":{"name":"text"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[67],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXLRefiner"},"widgets_values":[6,1024,1024,"a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"]},{"id":41,"type":"CLIPTextEncodeSDXLRefiner","pos":[1648,27],"size":[229.35106201171834,126],"flags":{},"order":17,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":64},{"name":"text","type":"STRING","link":66,"widget":{"name":"text"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[68],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXLRefiner"},"widgets_values":[3,1024,1024,"blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch"]},{"id":39,"type":"CheckpointLoaderSimple","pos":[1239,-166],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":8,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[62],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[63,64],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sdxl/sd_xl_refiner_1.0.safetensors"]},{"id":36,"type":"KSamplerAdvanced","pos":[1204,32],"size":[315,334],"flags":{},"order":18,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":53},{"name":"positive","type":"CONDITIONING","link":56},{"name":"negative","type":"CONDITIONING","link":55},{"name":"latent_image","type":"LATENT","link":54},{"name":"steps","type":"INT","link":73,"widget":{"name":"steps"},"slot_index":5},{"name":"end_at_step","type":"INT","link":75,"widget":{"name":"end_at_step"}}],"outputs":[{"name":"LATENT","type":"LATENT","links":[59],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSamplerAdvanced"},"widgets_values":["enable",2,"fixed",30,6.5,"dpmpp_2m_sde","exponential",0,25,"enable"]},{"id":45,"type":"Note","pos":[610,442],"size":{"0":210,"1":477.3874816894531},"flags":{},"order":9,"mode":0,"properties":{"text":""},"widgets_values":["SUPPORTED RESOLUTIONS\\n=====================\\n\\nratio  resolution\\n-----------------\\n0.5:   7041408\\n0.52:  7041344\\n0.57:  7681344\\n0.6:   7681280\\n0.68:  8321216\\n0.72:  8321152\\n0.78:  8961152\\n0.82:  8961088\\n0.88:  9601088\\n0.94:  9601024\\n1.0:  10241024\\n1.07:  1024960\\n1.13:  1088960\\n1.21:  1088896\\n1.29:  1152896\\n1.38:  1152832\\n1.46:  1216832\\n1.67:  1280768\\n1.75:  1344768\\n1.91:  1344704\\n2.0:   1408704\\n2.09:  1472704\\n2.4:   1536640\\n2.5:   1600640\\n2.89:  1664576\\n3.0:   1728576"],"color":"#432","bgcolor":"#653"},{"id":11,"type":"Note","pos":[68,-179],"size":[292.628344016358,171.6285590695581],"flags":{},"order":10,"mode":0,"properties":{"text":""},"widgets_values":["BASIC SDXL WORKFLOW BASE+REFINER\\n================================\\n\\nThis workflow showcases the suggested way of using SDXL with BASE and REFINER models.\\n\\nThe core of the composition is created by the BASE and the REFINER takes care of the minutiae."],"color":"#432","bgcolor":"#653"},{"id":29,"type":"Note","pos":[1113,602],"size":[218.08512297100106,207.59243181905276],"flags":{},"order":11,"mode":0,"properties":{"text":""},"widgets_values":["We are using primitives here to sync the base and the refiner.\\n\\nTOTAL STEPS is the total number of steps, STEPS SPENT ON BASE is the number of steps spent on the BASE model, the remaining will be handled by the REFINER.\\n\\nOf course total steps must be > steps spent on base."],"color":"#432","bgcolor":"#653"},{"id":38,"type":"KSamplerAdvanced","pos":[1950,-140],"size":[315,334],"flags":{},"order":19,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":62},{"name":"positive","type":"CONDITIONING","link":67},{"name":"negative","type":"CONDITIONING","link":68},{"name":"latent_image","type":"LATENT","link":59},{"name":"steps","type":"INT","link":74,"widget":{"name":"steps"}},{"name":"start_at_step","type":"INT","link":76,"widget":{"name":"start_at_step"}}],"outputs":[{"name":"LATENT","type":"LATENT","links":[69],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSamplerAdvanced"},"widgets_values":["disable",503501541605374,"fixed",30,6.5,"dpmpp_2m_sde","karras",25,10000,"disable"]},{"id":46,"type":"Note","pos":[1574,221],"size":[331.40839613549724,180.21395530098778],"flags":{},"order":12,"mode":0,"properties":{"text":""},"widgets_values":["ADVANCED KSAMPLER\\n=================\\n\\nNote that the first ksampler (base) has RETURN_WITH_LEFTOVER_NOISE enabled and the second (refiner) had ADD_NOISE disabled.\\n\\nThe first ksampler stops the generation at 25 steps and it's taken back from the refiner that generates the last 5 steps."],"color":"#432","bgcolor":"#653"},{"id":34,"type":"Note","pos":[870,-300],"size":[210,130],"flags":{},"order":13,"mode":0,"properties":{"text":""},"widgets_values":["WIDTH/HEIGHT and TARGET_WIDTH/HEIGHT are both 4 times the latent size.\\n\\nThis generally grants a higher definition image."],"color":"#432","bgcolor":"#653"}],"links":[[41,8,0,28,0,"IMAGE"],[45,31,0,30,1,"STRING"],[46,31,0,30,2,"STRING"],[47,32,0,33,1,"STRING"],[48,32,0,33,2,"STRING"],[49,4,1,30,0,"CLIP"],[50,4,1,33,0,"CLIP"],[53,4,0,36,0,"MODEL"],[54,5,0,36,3,"LATENT"],[55,33,0,36,2,"CONDITIONING"],[56,30,0,36,1,"CONDITIONING"],[58,37,0,8,1,"VAE"],[59,36,0,38,3,"LATENT"],[62,39,0,38,0,"MODEL"],[63,39,1,40,0,"CLIP"],[64,39,1,41,0,"CLIP"],[65,31,0,40,1,"STRING"],[66,32,0,41,1,"STRING"],[67,40,0,38,1,"CONDITIONING"],[68,41,0,38,2,"CONDITIONING"],[69,38,0,8,0,"LATENT"],[73,43,0,36,4,"INT"],[74,43,0,38,4,"INT"],[75,42,0,36,5,"INT"],[76,42,0,38,5,"INT"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic SDXL Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/webp_3jwAAwSV_1702934538301_raw.webp',
        description:`This basic workflow runs the base SDXL model with some optimization for SDXL. This can be useful for systems with limited resources as the refiner takes another 6GB or ram.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":35,"last_link_id":52,"nodes":[{"id":4,"type":"CheckpointLoaderSimple","pos":[30,50],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":0,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[20],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[49,50],"slot_index":1},{"name":"VAE","type":"VAE","links":[43],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sdxl/sd_xl_base_1.0_0.9vae.safetensors"]},{"id":33,"type":"CLIPTextEncodeSDXL","pos":[860,160],"size":{"0":220,"1":220},"flags":{},"order":8,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":50},{"name":"text_g","type":"STRING","link":47,"widget":{"name":"text_g"},"slot_index":1},{"name":"text_l","type":"STRING","link":48,"widget":{"name":"text_l"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[51],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXL"},"widgets_values":[4096,4096,0,0,4096,4096,"blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch","blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch"]},{"id":30,"type":"CLIPTextEncodeSDXL","pos":[860,-120],"size":{"0":220,"1":220},"flags":{},"order":9,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":49},{"name":"text_g","type":"STRING","link":45,"widget":{"name":"text_g"},"slot_index":1},{"name":"text_l","type":"STRING","link":46,"widget":{"name":"text_l"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[52],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncodeSDXL"},"widgets_values":[4096,4096,0,0,4096,4096,"a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k","a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"]},{"id":3,"type":"KSampler","pos":[1190,30],"size":{"0":300,"1":262},"flags":{},"order":10,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":20},{"name":"positive","type":"CONDITIONING","link":52},{"name":"negative","type":"CONDITIONING","link":51},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[42],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[2,"fixed",25,6.5,"dpmpp_2m_sde","exponential",1]},{"id":5,"type":"EmptyLatentImage","pos":[860,440],"size":{"0":220,"1":106},"flags":{},"order":1,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[1024,1024,1]},{"id":11,"type":"Note","pos":[80,-200],"size":[282.48542674442217,197.05842985845334],"flags":{},"order":2,"mode":0,"properties":{"text":""},"widgets_values":["BASIC SDXL WORKFLOW WITH BASE MODEL ONLY\\n========================================\\n\\nThis basic workflow only uses the BASE SDXL model. This can be useful for systems with limited resources as the REFINER takes another 6GB or ram.\\n\\nIf you use the embedded VAE be sure to download the \\"0.9vae\\" version because the 1.0 vae is considered defective."],"color":"#432","bgcolor":"#653"},{"id":29,"type":"Note","pos":[620,440],"size":[210,477.3874840224082],"flags":{},"order":3,"mode":0,"properties":{"text":""},"widgets_values":["SUPPORTED RESOLUTIONS\\n=====================\\n\\nratio  resolution\\n-----------------\\n0.5:   7041408\\n0.52:  7041344\\n0.57:  7681344\\n0.6:   7681280\\n0.68:  8321216\\n0.72:  8321152\\n0.78:  8961152\\n0.82:  8961088\\n0.88:  9601088\\n0.94:  9601024\\n1.0:  10241024\\n1.07:  1024960\\n1.13:  1088960\\n1.21:  1088896\\n1.29:  1152896\\n1.38:  1152832\\n1.46:  1216832\\n1.67:  1280768\\n1.75:  1344768\\n1.91:  1344704\\n2.0:   1408704\\n2.09:  1472704\\n2.4:   1536640\\n2.5:   1600640\\n2.89:  1664576\\n3.0:   1728576"],"color":"#432","bgcolor":"#653"},{"id":8,"type":"VAEDecode","pos":[1540,40],"size":{"0":140,"1":60},"flags":{},"order":11,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":42},{"name":"vae","type":"VAE","link":43}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[41],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":28,"type":"SaveImage","pos":[1730,50],"size":[688.1291672363286,728.7603461914064],"flags":{},"order":12,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":41}],"properties":{},"widgets_values":["ComfyUI"]},{"id":32,"type":"PrimitiveNode","pos":[460,180],"size":{"0":338.24078369140625,"1":179.58128356933594},"flags":{},"order":4,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[47,48],"widget":{"name":"text_g"},"slot_index":0}],"title":"negative","properties":{"Run widget replace on values":false},"widgets_values":["blurry, animation, 3d render, illustration, toy, puppet, claymation, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":34,"type":"Note","pos":[870,-300],"size":[210,130],"flags":{},"order":5,"mode":0,"properties":{"text":""},"widgets_values":["WIDTH/HEIGHT and TARGET_WIDTH/HEIGHT are both 4 times the latent size.\\n\\nThis generally grants a higher definition image."],"color":"#432","bgcolor":"#653"},{"id":31,"type":"PrimitiveNode","pos":[460,-90],"size":[338.2407698942967,179.5812845208606],"flags":{},"order":6,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[45,46],"widget":{"name":"text_g"},"slot_index":0}],"title":"positive","properties":{"Run widget replace on values":false},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":35,"type":"Note","pos":[464,-235],"size":[330.7162916580676,95.14419681769738],"flags":{},"order":7,"mode":0,"properties":{"text":""},"widgets_values":["Note that we send the same prompt to both TEXT_G and TEXT_L, you can experiment with different prompts but using the same seems to lead to more predictable results."],"color":"#432","bgcolor":"#653"}],"links":[[2,5,0,3,3,"LATENT"],[20,4,0,3,0,"MODEL"],[41,8,0,28,0,"IMAGE"],[42,3,0,8,0,"LATENT"],[43,4,2,8,1,"VAE"],[45,31,0,30,1,"STRING"],[46,31,0,30,2,"STRING"],[47,32,0,33,1,"STRING"],[48,32,0,33,2,"STRING"],[49,4,1,30,0,"CLIP"],[50,4,1,33,0,"CLIP"],[51,33,0,3,2,"CONDITIONING"],[52,30,0,3,1,"CONDITIONING"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic Second-Pass Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/image_jRx2H_U5_1702943992821_raw.jpg',
        description:`This workflow applies a second pass  of KSampler on top of this <a target="_blank" href="https://openart.ai/workflows/openart/basic-sd15-workflow-with-vae/XlPv7Qz9U3wOIDn5vSxM">basic SD 1.5 workflow with an external VAE</a> . Even at the same resolution (ie: without upscaling), the second pass can increase definition and fix small mistakes.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":28,"last_link_id":41,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[450,270],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":24}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6,34],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":4,"type":"CheckpointLoaderSimple","pos":[30,150],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":0,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[20,32],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[23,24],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":5,"type":"EmptyLatentImage","pos":[600,490],"size":{"0":220,"1":106},"flags":{},"order":1,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":3,"type":"KSampler","pos":[900,190],"size":{"0":300,"1":262},"flags":{},"order":6,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":20},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[36,38],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":15,"type":"VAELoader","pos":[880,510],"size":{"0":315,"1":58},"flags":{},"order":2,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12,39],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":26,"type":"VAEDecode","pos":[1312,532],"size":{"0":140,"1":60},"flags":{},"order":8,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":38},{"name":"vae","type":"VAE","link":39}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[40],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":8,"type":"VAEDecode","pos":[1650,200],"size":{"0":140,"1":60},"flags":{},"order":9,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":37},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[41],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":27,"type":"PreviewImage","pos":[1515,525],"size":[588.3998002929688,602.6846180419923],"flags":{},"order":10,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":40}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":28,"type":"SaveImage","pos":[2134,512],"size":[567.277800292969,611.7056180419925],"flags":{},"order":11,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":41}],"properties":{},"widgets_values":["ComfyUI"]},{"id":25,"type":"KSampler","pos":[1270,130],"size":{"0":300,"1":262},"flags":{},"order":7,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":32},{"name":"positive","type":"CONDITIONING","link":33},{"name":"negative","type":"CONDITIONING","link":34},{"name":"latent_image","type":"LATENT","link":36}],"outputs":[{"name":"LATENT","type":"LATENT","links":[37],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[1001,"fixed",20,6,"dpmpp_2m","karras",0.45]},{"id":6,"type":"CLIPTextEncode","pos":[450,50],"size":{"0":370,"1":160},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":23}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4,33],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic raccoon wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":11,"type":"Note","pos":[1276,-105],"size":[290.6730059814454,181.583876953125],"flags":{},"order":3,"mode":0,"properties":{"text":""},"widgets_values":["SIMPLE SECOND PASS\\n==================\\n\\nApplying a second pass even at the same resolution (ie: without upscaling) can increase definition and fix small mistakes.\\n\\nIncreasing the DENOISE adds more details but also changes the original reference more (the first pass)."],"color":"#432","bgcolor":"#653"}],"links":[[2,5,0,3,3,"LATENT"],[4,6,0,3,1,"CONDITIONING"],[6,7,0,3,2,"CONDITIONING"],[12,15,0,8,1,"VAE"],[20,4,0,3,0,"MODEL"],[23,4,1,6,0,"CLIP"],[24,4,1,7,0,"CLIP"],[32,4,0,25,0,"MODEL"],[33,6,0,25,1,"CONDITIONING"],[34,7,0,25,2,"CONDITIONING"],[36,3,0,25,3,"LATENT"],[37,25,0,8,0,"LATENT"],[38,3,0,26,0,"LATENT"],[39,15,0,26,1,"VAE"],[40,26,0,27,0,"IMAGE"],[41,8,0,28,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Batch Generation Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/image_qmd3m0_k_1702943062775_raw.jpg',
        description:`This workflow can batch generate images instead of one at at time, by using the Latent From Batch node. It helps get more results at a time.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":24,"last_link_id":30,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[450,270],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":24}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":5,"type":"EmptyLatentImage","pos":[600,490],"size":{"0":220,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,4]},{"id":4,"type":"CheckpointLoaderSimple","pos":[30,150],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":1,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[20],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[23,24],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":3,"type":"KSampler","pos":[900,190],"size":{"0":300,"1":262},"flags":{},"order":6,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":20},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7,25],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":15,"type":"VAELoader","pos":[880,510],"size":{"0":315,"1":58},"flags":{},"order":2,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12,27],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":8,"type":"VAEDecode","pos":[1250,190],"size":{"0":140,"1":60},"flags":{},"order":7,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[29],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":20,"type":"VAEDecode","pos":[1580,750],"size":{"0":140,"1":60},"flags":{},"order":10,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":26},{"name":"vae","type":"VAE","link":27}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[30],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":22,"type":"PreviewImage","pos":[1450,200],"size":[436.18048242187524,454.7486420898439],"flags":{},"order":9,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":29}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":23,"type":"SaveImage","pos":[1770,750],"size":[427.6204824218753,479.064642089844],"flags":{},"order":11,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":30}],"properties":{},"widgets_values":["ComfyUI"]},{"id":6,"type":"CLIPTextEncode","pos":[450,50],"size":{"0":370,"1":160},"flags":{},"order":4,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":23}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":19,"type":"LatentFromBatch","pos":[1310,750],"size":[210,82],"flags":{},"order":8,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":25}],"outputs":[{"name":"LATENT","type":"LATENT","links":[26],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"LatentFromBatch"},"widgets_values":[3,1]},{"id":11,"type":"Note","pos":[610,650],"size":[220,230],"flags":{},"order":3,"mode":0,"properties":{"text":""},"widgets_values":["LATENT BATCH\\n============\\n\\nIncrease the batch size to get more result.\\n\\nYou can extract one (or more) of the results with the \\"Latent From Batch\\" node."],"color":"#432","bgcolor":"#653"}],"links":[[2,5,0,3,3,"LATENT"],[4,6,0,3,1,"CONDITIONING"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[12,15,0,8,1,"VAE"],[20,4,0,3,0,"MODEL"],[23,4,1,6,0,"CLIP"],[24,4,1,7,0,"CLIP"],[25,3,0,19,0,"LATENT"],[26,19,0,20,0,"LATENT"],[27,15,0,20,1,"VAE"],[29,8,0,22,0,"IMAGE"],[30,20,0,23,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic LoRA Workflow",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/webp_v5L3bGqX_1702941891063_raw.webp',
        description:`This workflow loads an additional LoRA on top of the base model.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":17,"last_link_id":17,"nodes":[{"id":7,"type":"CLIPTextEncode","pos":[820,400],"size":{"0":370,"1":160},"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":16}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[6],"slot_index":0}],"title":"CLIP Text Encode (Negative)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, illustration, toy, clay, low quality, flag, nasa, mission patch"],"color":"#322","bgcolor":"#533"},{"id":6,"type":"CLIPTextEncode","pos":[820,180],"size":{"0":370,"1":160},"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":15}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[4],"slot_index":0}],"title":"CLIP Text Encode (Positive)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["a photo of an anthropomorphic fox wearing a spacesuit inside a sci-fi spaceship\\n\\ncinematic, dramatic lighting, high resolution, detailed, 4k"],"color":"#232","bgcolor":"#353"},{"id":8,"type":"VAEDecode","pos":[1620,320],"size":{"0":140,"1":60},"flags":{},"order":8,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":7},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[9],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":9,"type":"SaveImage","pos":[1810,320],"size":{"0":410,"1":460},"flags":{},"order":9,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":9}],"properties":{},"widgets_values":["Result"]},{"id":5,"type":"EmptyLatentImage","pos":[970,620],"size":{"0":220,"1":106},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[2],"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":15,"type":"VAELoader","pos":[1250,640],"size":{"0":315,"1":58},"flags":{},"order":1,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":3,"type":"KSampler","pos":[1270,320],"size":{"0":300,"1":262},"flags":{},"order":7,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":17},{"name":"positive","type":"CONDITIONING","link":4},{"name":"negative","type":"CONDITIONING","link":6},{"name":"latent_image","type":"LATENT","link":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[7],"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[8,"fixed",25,6.5,"dpmpp_2m","karras",1]},{"id":4,"type":"CheckpointLoaderSimple","pos":[20,280],"size":{"0":328.5366516113281,"1":98},"flags":{},"order":2,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[13],"slot_index":0},{"name":"CLIP","type":"CLIP","links":[14],"slot_index":1},{"name":"VAE","type":"VAE","links":[],"slot_index":2}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":17,"type":"LoraLoader","pos":[420,280],"size":{"0":315,"1":126},"flags":{},"order":4,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":13},{"name":"clip","type":"CLIP","link":14}],"outputs":[{"name":"MODEL","type":"MODEL","links":[17],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[15,16],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"LoraLoader"},"widgets_values":["more_details.safetensors",1,1]},{"id":11,"type":"Note","pos":[420,-10],"size":[260,230],"flags":{},"order":3,"mode":0,"properties":{"text":""},"widgets_values":["LORA\\n====\\n\\nSTRENGTH_MODEL and STRENGTH_CLIP are supposed to have the same value, but you can play with the values to get different results.\\n\\nThe CLIP is responsible of translating the prompts. The MODEL is the actual trained data.\\n\\n** LORAs can be daisy-chained! You can have as many as you want **"],"color":"#432","bgcolor":"#653"}],"links":[[2,5,0,3,3,"LATENT"],[4,6,0,3,1,"CONDITIONING"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[9,8,0,9,0,"IMAGE"],[12,15,0,8,1,"VAE"],[13,4,0,17,0,"MODEL"],[14,4,1,17,1,"CLIP"],[15,17,1,6,0,"CLIP"],[16,17,1,7,0,"CLIP"],[17,17,0,3,0,"MODEL"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },
    {
        title:"Basic IPAdapter",
        type:'template',
        thumbnail:'https://cdn.openart.ai/workflow_thumbnails/4pYEgRw3JXVFu5elJKeR/image_KdBztP1T_1702945457521_512.webp',
        description:`This workflows is a very simple workflow to use IPAdapter IP-Adapter is an effective and lightweight adapter to achieve image prompt capability for stable diffusion models.`,
        categories:[categories[1]],
        initialWorkflow:`{"last_node_id":14,"last_link_id":13,"nodes":[{"id":10,"type":"EmptyLatentImage","pos":[650,590],"size":{"0":210,"1":110},"flags":{},"order":0,"mode":0,"outputs":[{"name":"LATENT","type":"LATENT","links":[10],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[512,512,1]},{"id":8,"type":"CLIPTextEncode","pos":[650,420],"size":{"0":210,"1":120},"flags":{},"order":8,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":6}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[9],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, horror"],"color":"#322","bgcolor":"#533"},{"id":7,"type":"CLIPTextEncode","pos":[650,250],"size":{"0":210,"1":120},"flags":{},"order":7,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":5}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[8],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["beautiful renaissance girl, detailed"],"color":"#232","bgcolor":"#353"},{"id":11,"type":"VAEDecode","pos":[1300,170],"size":{"0":140,"1":50},"flags":{},"order":11,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":11},{"name":"vae","type":"VAE","link":12}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[13],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":2,"type":"VAELoader","pos":[940,480],"size":{"0":300,"1":60},"flags":{},"order":1,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[12],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.safetensors"]},{"id":12,"type":"SaveImage","pos":[1300,270],"size":{"0":400,"1":450},"flags":{},"order":12,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":13}],"properties":{},"widgets_values":["IPAdapter"]},{"id":6,"type":"LoadImage","pos":[40,60],"size":{"0":220,"1":320},"flags":{},"order":2,"mode":0,"outputs":[{"name":"IMAGE","type":"IMAGE","links":[3],"shape":3,"slot_index":0},{"name":"MASK","type":"MASK","links":null,"shape":3}],"properties":{"Node name for S&R":"LoadImage"},"widgets_values":["venere.jpg","image"]},{"id":9,"type":"KSampler","pos":[930,170],"size":{"0":315,"1":262},"flags":{},"order":10,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":7},{"name":"positive","type":"CONDITIONING","link":8},{"name":"negative","type":"CONDITIONING","link":9},{"name":"latent_image","type":"LATENT","link":10}],"outputs":[{"name":"LATENT","type":"LATENT","links":[11],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[0,"fixed",25,6,"ddim","ddim_uniform",1]},{"id":4,"type":"CLIPVisionLoader","pos":[290,170],"size":{"0":300,"1":60},"flags":{},"order":3,"mode":0,"outputs":[{"name":"CLIP_VISION","type":"CLIP_VISION","links":[2],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPVisionLoader"},"widgets_values":["IPAdapter_image_encoder_sd15.safetensors"]},{"id":1,"type":"CheckpointLoaderSimple","pos":[290,280],"size":{"0":300,"1":100},"flags":{},"order":4,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[4],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[5,6],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":null,"shape":3}],"properties":{"Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd15/dreamshaper_8.safetensors"]},{"id":5,"type":"IPAdapterApply","pos":[651,-57],"size":{"0":210,"1":258},"flags":{},"order":9,"mode":0,"inputs":[{"name":"ipadapter","type":"IPADAPTER","link":1},{"name":"clip_vision","type":"CLIP_VISION","link":2},{"name":"image","type":"IMAGE","link":3},{"name":"model","type":"MODEL","link":4},{"name":"attn_mask","type":"MASK","link":null}],"outputs":[{"name":"MODEL","type":"MODEL","links":[7],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"IPAdapterApply"},"widgets_values":[0.85,0,"original",0,1,false]},{"id":3,"type":"IPAdapterModelLoader","pos":[290,60],"size":{"0":300,"1":60},"flags":{},"order":5,"mode":0,"outputs":[{"name":"IPADAPTER","type":"IPADAPTER","links":[1],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"IPAdapterModelLoader"},"widgets_values":["ip-adapter_sd15.safetensors"]},{"id":13,"type":"Note","pos":[131,-270],"size":[456.8177419906998,273.55983091565],"flags":{},"order":6,"mode":0,"properties":{"text":""},"widgets_values":["BASIC IPADAPTER\\n===============\\n\\nBe careful when selecting the models!\\n\\nThe IPAdapter model has to match the CLIP vision encoder and of course the main checkpoint.\\n\\nAll SD15 models and all models ending with \\"vit-h\\" use the SD15 CLIP vision.\\n\\nOne of the SDXL models and all models ending with \\"vit-g\\" use the SDXL CLIP vision.\\n\\nPLUS models use more tokens and are stronger. LIGHT models have a very light impact. FACE and FULL-FACE are only to describe faces (they are not face swap!)"],"color":"#432","bgcolor":"#653"}],"links":[[1,3,0,5,0,"IPADAPTER"],[2,4,0,5,1,"CLIP_VISION"],[3,6,0,5,2,"IMAGE"],[4,1,0,5,3,"MODEL"],[5,1,1,7,0,"CLIP"],[6,1,1,8,0,"CLIP"],[7,5,0,9,0,"MODEL"],[8,7,0,9,1,"CONDITIONING"],[9,8,0,9,2,"CONDITIONING"],[10,10,0,9,3,"LATENT"],[11,9,0,11,0,"LATENT"],[12,2,0,11,1,"VAE"],[13,11,0,12,0,"IMAGE"]],"groups":[],"config":{},"extra":{},"version":0.4}`
    },

]
